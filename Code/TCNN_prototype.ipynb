{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f2aea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92908147",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\n",
    "    \"HR\", \"O2Sat\", \"Temp\", \"SBP\", \"MAP\", \"Resp\", \"pH\",\n",
    "    \"BUN\", \"WBC\", \"Platelets\", \"Magnesium\", \"Potassium\"\n",
    "]\n",
    "LABEL_COL = \"SepsisLabel\"\n",
    "META_COLS = [\"PatientID\", \"Hour\"]\n",
    "\n",
    "def build_patient_sequences_simple(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.sort_values([\"PatientID\", \"Hour\"]).reset_index(drop=True)\n",
    "\n",
    "    # Keep only what we care about\n",
    "    keep_cols = META_COLS + FEATURE_COLS + [LABEL_COL]\n",
    "    df = df[keep_cols]\n",
    "\n",
    "    patients = []\n",
    "\n",
    "    # Precompute global means for fallback impute at the end\n",
    "    global_means = df[FEATURE_COLS].mean(skipna=True)\n",
    "\n",
    "    for pid, g in df.groupby(\"PatientID\"):\n",
    "        g = g.sort_values(\"Hour\")\n",
    "\n",
    "        # Patient label: septic if ever SepsisLabel==1\n",
    "        y_patient = int(g[LABEL_COL].fillna(0).max())\n",
    "\n",
    "        # Grab features only\n",
    "        X = g[FEATURE_COLS].copy()\n",
    "\n",
    "        # 1. forward fill within patient\n",
    "        X = X.ffill()\n",
    "\n",
    "        # 2. fill any still-missing with global means\n",
    "        X = X.fillna(global_means)\n",
    "\n",
    "        # convert to tensor [T, F]\n",
    "        X_tensor = torch.tensor(X.to_numpy(dtype=np.float32))\n",
    "\n",
    "        patients.append({\n",
    "            \"patient_id\": pid,\n",
    "            \"series\": X_tensor,                        # [T, F]\n",
    "            \"label\": torch.tensor(y_patient).float(), # scalar\n",
    "            \"length\": X_tensor.shape[0],\n",
    "        })\n",
    "\n",
    "    in_features = len(FEATURE_COLS)\n",
    "    return patients, in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6a9e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TCNDataset(Dataset):\n",
    "    def __init__(self, patients_list):\n",
    "        self.patients = patients_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.patients[idx]\n",
    "        return {\n",
    "            \"series\": p[\"series\"],        # [T, F]\n",
    "            \"label\": p[\"label\"],          # scalar\n",
    "            \"length\": p[\"length\"],        # int\n",
    "            \"patient_id\": p[\"patient_id\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "039a5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_tcn(batch):\n",
    "    lengths = [b[\"length\"] for b in batch]\n",
    "    max_len = max(lengths)\n",
    "    feat_dim = batch[0][\"series\"].shape[1]\n",
    "    B = len(batch)\n",
    "\n",
    "    feats = torch.zeros(B, max_len, feat_dim, dtype=torch.float32)\n",
    "    time_mask = torch.zeros(B, max_len, dtype=torch.float32)\n",
    "    labels = torch.zeros(B, dtype=torch.float32)\n",
    "    last_idx = torch.zeros(B, dtype=torch.long)\n",
    "\n",
    "    patient_ids = []\n",
    "\n",
    "    for i, b in enumerate(batch):\n",
    "        T = b[\"length\"]\n",
    "        feats[i, :T, :] = b[\"series\"]\n",
    "        time_mask[i, :T] = 1.0\n",
    "        labels[i] = b[\"label\"]\n",
    "        last_idx[i] = T - 1\n",
    "        patient_ids.append(b[\"patient_id\"])\n",
    "\n",
    "    # TCN expects [B, C, T]\n",
    "    feats = feats.permute(0, 2, 1)\n",
    "\n",
    "    return {\n",
    "        \"x\": feats,            # [B, feat_dim, max_len]\n",
    "        \"mask\": time_mask,     # [B, max_len] (not strictly needed for patient-level loss)\n",
    "        \"y\": labels,           # [B]\n",
    "        \"last_idx\": last_idx,  # [B]\n",
    "        \"patient_id\": patient_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5db446da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, dilation, dropout=0.1):\n",
    "        super().__init__()\n",
    "        pad = (kernel_size - 1) * dilation\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch,\n",
    "                               kernel_size=kernel_size,\n",
    "                               padding=pad,\n",
    "                               dilation=dilation)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch,\n",
    "                               kernel_size=kernel_size,\n",
    "                               padding=pad,\n",
    "                               dilation=dilation)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.residual = (\n",
    "            nn.Conv1d(in_ch, out_ch, kernel_size=1)\n",
    "            if in_ch != out_ch else nn.Identity()\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in [self.conv1, self.conv2]:\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        if isinstance(self.residual, nn.Conv1d):\n",
    "            nn.init.kaiming_normal_(self.residual.weight)\n",
    "            if self.residual.bias is not None:\n",
    "                nn.init.zeros_(self.residual.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, T]\n",
    "        T = x.size(-1)\n",
    "\n",
    "        y = self.conv1(x)[:, :, :T]\n",
    "        y = self.relu1(y)\n",
    "        y = self.drop1(y)\n",
    "\n",
    "        y = self.conv2(y)[:, :, :T]\n",
    "        y = self.relu2(y)\n",
    "        y = self.drop2(y)\n",
    "\n",
    "        res = self.residual(x)[:, :, :T]\n",
    "\n",
    "        return y + res  # residual\n",
    "\n",
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, in_ch, hidden_ch=64, num_levels=4, kernel_size=3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        ch_in = in_ch\n",
    "        for i in range(num_levels):\n",
    "            dilation = 2 ** i  # 1,2,4,8,...\n",
    "            ch_out = hidden_ch\n",
    "            layers.append(\n",
    "                TemporalBlock(\n",
    "                    in_ch=ch_in,\n",
    "                    out_ch=ch_out,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=dilation,\n",
    "                    dropout=0.1,\n",
    "                )\n",
    "            )\n",
    "            ch_in = ch_out\n",
    "\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.head = nn.Conv1d(ch_in, 1, kernel_size=1)  # per-timestep logit\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, in_ch, T]\n",
    "        h = self.tcn(x)        # [B, hidden_ch, T]\n",
    "        logits = self.head(h)  # [B, 1, T]\n",
    "        logits = logits.squeeze(1)  # [B, T]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c40c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, optimizer, device):\n",
    "    model.train()\n",
    "    x = batch[\"x\"].to(device)             # [B, C, T]\n",
    "    y = batch[\"y\"].to(device)             # [B]\n",
    "    last_idx = batch[\"last_idx\"].to(device)\n",
    "\n",
    "    logits_time = model(x)                # [B, T]\n",
    "    B = logits_time.shape[0]\n",
    "    logits_last = logits_time[torch.arange(B, device=device), last_idx]\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss = loss_fn(logits_last, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits_last)\n",
    "        preds = (probs > 0.5).float()\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940594b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | loss=8.7165 | acc=0.8750\n",
      "epoch 1 | loss=0.5894 | acc=0.8750\n",
      "epoch 2 | loss=0.0000 | acc=1.0000\n",
      "epoch 3 | loss=0.0000 | acc=1.0000\n",
      "epoch 4 | loss=4.6714 | acc=0.8750\n"
     ]
    }
   ],
   "source": [
    "#File path for training data. \n",
    "\n",
    "csv_path = \"subset_train.csv\"\n",
    "patients, in_ch = build_patient_sequences_simple(csv_path)\n",
    "\n",
    "dataset = TCNDataset(patients)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_tcn,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TCNModel(in_ch=in_ch, hidden_ch=64, num_levels=4, kernel_size=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch in loader:\n",
    "        loss, acc = train_step(model, batch, optimizer, device)\n",
    "    print(f\"epoch {epoch} | loss={loss:.4f} | acc={acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57076514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_csv = \"train.csv\"\n",
    "val_csv   = \"subset_train.csv\"\n",
    "\n",
    "#train_patients, in_ch = build_patient_sequences_simple(train_csv)\n",
    "val_patients, _       = build_patient_sequences_simple(val_csv)\n",
    "\n",
    "#train_dataset = TCNDataset(train_patients)\n",
    "val_dataset   = TCNDataset(val_patients)\n",
    "\n",
    "#train_loader = DataLoader(\n",
    "#    train_dataset,\n",
    "#    batch_size=16,\n",
    "#    shuffle=True,\n",
    "#    collate_fn=collate_tcn,\n",
    "#)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,        # important: don't shuffle eval\n",
    "    collate_fn=collate_tcn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d1d6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    all_losses = []\n",
    "    all_accs = []\n",
    "\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"x\"].to(device)             # [B, C, T]\n",
    "        y = batch[\"y\"].to(device)             # [B]\n",
    "        last_idx = batch[\"last_idx\"].to(device)\n",
    "\n",
    "        logits_time = model(x)                # [B, T]\n",
    "        B = logits_time.shape[0]\n",
    "        logits_last = logits_time[torch.arange(B, device=device), last_idx]  # [B]\n",
    "\n",
    "        loss = loss_fn(logits_last, y)\n",
    "\n",
    "        probs = torch.sigmoid(logits_last)    # [B]\n",
    "        preds = (probs > 0.5).float()\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        all_losses.append(loss.item())\n",
    "        all_accs.append(acc.item())\n",
    "\n",
    "        all_probs.append(probs.cpu())\n",
    "        all_targets.append(y.cpu())\n",
    "\n",
    "    # concat for possible AUROC / etc.\n",
    "    all_probs = torch.cat(all_probs)      # shape [N_val_patients]\n",
    "    all_targets = torch.cat(all_targets)  # shape [N_val_patients]\n",
    "\n",
    "    avg_loss = float(torch.tensor(all_losses).mean())\n",
    "    avg_acc  = float(torch.tensor(all_accs).mean())\n",
    "\n",
    "    return {\n",
    "        \"val_loss\": avg_loss,\n",
    "        \"val_acc\": avg_acc,\n",
    "        \"probs\": all_probs,\n",
    "        \"targets\": all_targets,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6464cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 0.7443217039108276, 'val_acc': 0.96875, 'probs': tensor([1.8070e-18, 1.0000e+00, 7.7453e-18, 2.7479e-05, 4.3148e-01, 4.3466e-22,\n",
      "        8.0270e-07, 9.6127e-06, 1.0522e-11, 1.0000e+00, 9.0951e-13, 5.6985e-09,\n",
      "        1.6963e-16, 3.0734e-10, 2.2778e-19, 3.0689e-37, 8.7208e-01, 0.0000e+00,\n",
      "        2.3087e-11, 3.3978e-20, 0.0000e+00, 5.6141e-12, 1.2921e-28, 1.0856e-25,\n",
      "        0.0000e+00, 0.0000e+00, 2.9066e-28, 1.1929e-23, 1.1174e-11, 2.3394e-09,\n",
      "        6.0702e-27, 1.0826e-09, 4.1535e-09, 3.4999e-09, 1.6795e-11, 5.2527e-08,\n",
      "        2.1569e-25, 1.3614e-22, 1.0000e+00, 2.9687e-19, 0.0000e+00, 3.0680e-21,\n",
      "        3.1024e-10, 1.6808e-18, 6.3880e-34, 1.9359e-22, 0.0000e+00, 1.2504e-38,\n",
      "        7.8938e-31, 5.6591e-11, 2.2481e-25, 1.9720e-16, 6.5417e-17, 0.0000e+00,\n",
      "        2.7177e-14, 4.1250e-29, 3.0286e-30, 3.0636e-38, 2.6874e-29, 7.4694e-24,\n",
      "        0.0000e+00, 5.2262e-34, 2.8284e-11, 5.0453e-26, 1.9816e-20, 3.5343e-21,\n",
      "        2.7986e-37, 0.0000e+00, 9.9981e-01, 1.4325e-25, 4.4742e-04, 0.0000e+00,\n",
      "        1.0647e-06, 2.1423e-32, 0.0000e+00, 1.4706e-12, 9.1092e-31, 1.0000e+00,\n",
      "        1.4805e-37, 7.2060e-20, 2.0784e-13, 9.1628e-09, 4.6442e-36, 1.8596e-36,\n",
      "        8.3029e-31, 5.5758e-36, 7.9044e-03, 0.0000e+00, 7.5911e-31, 3.0584e-25,\n",
      "        1.2890e-17, 0.0000e+00, 7.3325e-21, 7.2519e-06, 1.4311e-03, 3.0240e-17,\n",
      "        2.4913e-10, 1.1355e-05, 3.1852e-21, 1.0010e-32, 2.4719e-11, 9.9941e-01,\n",
      "        2.6934e-22, 1.8071e-15, 7.1029e-15, 0.0000e+00, 2.4324e-21, 1.0021e-18,\n",
      "        4.2687e-19, 3.8397e-20, 1.4936e-10, 0.0000e+00, 2.1437e-29, 0.0000e+00,\n",
      "        2.3612e-24, 9.2240e-24, 2.0646e-20, 1.4821e-22, 3.5435e-36, 0.0000e+00]), 'targets': tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "model.eval()                # switch to inference mode\n",
    "metrics = eval_epoch(model, val_loader, device)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1224378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val AUROC: 0.9069069069069069 val AUPRC: 0.7461920795254129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "val_auc = roc_auc_score(metrics[\"targets\"].numpy(),\n",
    "                        metrics[\"probs\"].numpy())\n",
    "val_auprc = average_precision_score(metrics[\"targets\"].numpy(),\n",
    "                                    metrics[\"probs\"].numpy())\n",
    "print(\"val AUROC:\", val_auc, \"val AUPRC:\", val_auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ac536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a99f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
